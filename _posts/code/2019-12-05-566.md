---
layout: project
title: Deep Learning
category: code
scheme-bg: "#fff"
scheme-bg-light: "#fff"
scheme-text: "#123"
permalink: /566/
---

[View this project on GitHub](https://github.com/nspotrepka/566)

# Project Description

In this project, we uncover hidden possibilities for using deep neural networks
in the creative domain. Beginning with the intention of translating image into
music and vice versa, we stubble upon an entirely different use case for our
CycleGAN model. By applying a filter to our training images, we produce a
two-step transformation that creates artifacts to obtain a unique style.
Some results are pictured below.

# Examples

In each of the examples below, we train our model on two datasets. The first
dataset is a set of standard images. The second dataset varies with each example
and is described in the subheading. Our model trains for 200 epochs in every
example.

## 2-channel Audio Files

In this example, we use 2-channel audio data, reshaped into 2 dimensions.

<table style="table-layout: fixed; width: 100%;">
    <tr>
        <td>Original</td>
        <td>Transformed</td>
        <td>Cycle</td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/image/original_lena_first.png" style="width: 100%"></td>
        <td></td>
        <td><img src="/assets/img/566/image/cycle_lena_first.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/image/original_tree_first.png" style="width: 100%"></td>
        <td></td>
        <td><img src="/assets/img/566/image/cycle_tree_first.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td>
            <audio controls>
                <source src="/assets/img/566/audio/original_sun.wav" type="audio/wav">
            </audio>
        </td>
        <td></td>
        <td>
            <audio controls>
                <source src="/assets/img/566/audio/cycle_sun.wav" type="audio/wav">
            </audio>
        </td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/audio/original_sun.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/audio/fake_sun_first.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/audio/cycle_sun.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td>
            <audio controls>
                <source src="/assets/img/566/audio/original_deltaheavy.wav" type="audio/wav">
            </audio>
        </td>
        <td></td>
        <td>
            <audio controls>
                <source src="/assets/img/566/audio/cycle_deltaheavy.wav" type="audio/wav">
            </audio>
        </td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/audio/original_deltaheavy.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/audio/fake_deltaheavy_first.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/audio/cycle_deltaheavy.png" style="width: 100%"></td>
    </tr>
</table>

Audio-image transformation is abstract and interesting, yet unrefined.

Both cycle transformations show a change in dynamic contrast, loss of
high-frequency content, and artifacts.

## MIDI Files

In this example, we use polyphonic MIDI data, represented as black and white
images.

<table style="table-layout: fixed; width: 100%;">
    <tr>
        <td>Original</td>
        <td>Transformed</td>
        <td>Cycle</td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/midi/original_lena.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/fake_lena.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/cycle_lena_midi.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/midi/original_tree.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/fake_tree.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/cycle_tree_midi.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/midi/original_madonna.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/fake_madonna.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/cycle_madonna.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/midi/original_scott_joplin.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/fake_scott_joplin.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/midi/cycle_scott_joplin.png" style="width: 100%"></td>
    </tr>
</table>

Image-MIDI and MIDI-image transformations produce interesting style transfer
results. The abstract nature of MIDI-image transformation seems to arise from an
increase in information without structure. Using an intermediate training layer
and including an additional layer of training data may fix this issue.

As we can see, image-MIDI-image cycle transformation is less successful than
its audio counterpart due to the low amount of information in our MIDI
representation. Using a more complex representation may fix this issue.

## 4X Downsampled Cubic Interpolated Images

This is our key result. We use the same images, downsampled by a factor of 4
and then upsampled using cubic interpolation.

<table style="table-layout: fixed; width: 100%;">
    <tr>
        <td>Original</td>
        <td>Transformed</td>
        <td>Cycle</td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/blur/original_lena4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/fake_lena4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/cycle_lena4.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/blur/original_tree4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/fake_tree4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/cycle_tree4.png" style="width: 100%"></td>
    </tr>
</table>

By applying a blurring filter to our original set of images, we obtain a second
dataset that is similar to the first. We then use a CycleGAN model to attempt to
recreate the original image. Since our filter is not equivalent to the CycleGAN
transformation, we get artifacts, and depending on which filter we use, we may
get different artifacts. Thus, we obtain can an original style with each filter.
Other ideas for filters could be:

* Spatial Transformations:
  * Tessellation
  * Fractal Mapping
  * Pixel Sorting
* Color Transformations:
  * Hue/Saturation Blurring
  * Hue Shifting
  * Bit Reduction

We now transform low-quality images generated by a variational autoencoder. The
result of this upsampling process is more artistic than useful, but nonetheless,
it is worth pointing out the potential here.

<table style="table-layout: fixed; width: 100%;">
    <tr>
        <td>Original</td>
        <td>Transformed</td>
        <td>Cycle</td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/blur/original_face.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/fake_face.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/cycle_face.png" style="width: 100%"></td>
    </tr>
    <tr>
        <td><img src="/assets/img/566/blur/original_dog4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/fake_dog4.png" style="width: 100%"></td>
        <td><img src="/assets/img/566/blur/cycle_dog4.png" style="width: 100%"></td>
    </tr>
</table>

[View this project on GitHub](https://github.com/nspotrepka/566)
